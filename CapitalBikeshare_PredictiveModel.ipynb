{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOCUYA7gvW1iYjHBzN63gmq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkoide01/BikeShareRiderPredictor_UChicago_MachineLearningFinalProject/blob/main/CapitalBikeshare_PredictiveModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirEJGug2Soh",
        "outputId": "b2414924-32ed-4f51-d6b7-2d0eea7a48ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "# Set the display format for floating-point numbers\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# Mount Google Drive: \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load Bike Sharing Service CSV data into dataframe"
      ],
      "metadata": {
        "id": "VTy-2A_N2rc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the directory path: \n",
        "path = \"/content/drive/My Drive/MSCA31009MLPA_FinalProject/data\"\n",
        "!ls \"/content/drive/My Drive/MSCA31009MLPA_FinalProject/data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihtFR8pe2qrR",
        "outputId": "45017e4f-f183-4296-a617-be915ef0119f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2010-2017  2021\t\t     post-pandemic\t      pre_pandemic_data2.csv\n",
            "2018\t   2022\t\t     post_pandemic_data2.csv  pre_pandemic_data.csv\n",
            "2019\t   DF_2010-2022.csv  post_pandemic_data.csv\n",
            "2020\t   Merged_data\t     pre-pandemic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the two pre and post pandemic data\n",
        "file_name1 = '/pre_pandemic_data2.csv'\n",
        "file_name2 = '/post_pandemic_data2.csv'\n",
        "\n",
        "\n",
        "pre_pandemic_data = pd.read_csv(path+file_name1)\n",
        "print(pre_pandemic_data.head())\n",
        "print(pre_pandemic_data.shape)\n",
        "post_pandemic_data = pd.read_csv(path+file_name2)\n",
        "print(post_pandemic_data.head())\n",
        "print(post_pandemic_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSs8o8Dj2yKR",
        "outputId": "c60c73c1-a8b1-4ea9-ed2a-8f84183bce12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Start station number  End station number Member type  \\\n",
            "0           0                 31634               31208      Member   \n",
            "1           1                 31258               31270      Casual   \n",
            "2           2                 31289               31222      Casual   \n",
            "3           3                 31289               31222      Casual   \n",
            "4           4                 31258               31270      Casual   \n",
            "\n",
            "  day_of_week    month  year  Total trip count  \n",
            "0      Sunday  January  2017                 2  \n",
            "1      Sunday  January  2017                 4  \n",
            "2      Sunday  January  2017                19  \n",
            "3      Sunday  January  2017                19  \n",
            "4      Sunday  January  2017                 4  \n",
            "(25915290, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4d1f5ffb333d>:9: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  post_pandemic_data = pd.read_csv(path+file_name2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 Start station number End station number Member type day_of_week  \\\n",
            "0           0             31318.00           31405.00      Casual      Friday   \n",
            "1           1             31270.00           31663.00      Member      Friday   \n",
            "2           2             31926.00           31036.00      Member    Thursday   \n",
            "3           3             31907.00           31047.00      Member    Thursday   \n",
            "4           4             31931.00           31047.00      Casual      Monday   \n",
            "\n",
            "     month  year  Total trip count  \n",
            "0  January  2021                 1  \n",
            "1  January  2021                 1  \n",
            "2  January  2021                 1  \n",
            "3  January  2021                 1  \n",
            "4  January  2021                 1  \n",
            "(6045461, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KUKItR_a2q_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Run the Predictive models: LSTM Model and Random-Forest regressor as Ensemble model"
      ],
      "metadata": {
        "id": "wEC20DsG4RIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for running LSTM model and RF model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,  OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "vve1Y1JCedk9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WcT85MTe5ne",
        "outputId": "776aeee4-929e-46fa-a934-363fa9e6dc34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Start station number', 'End station number',\n",
              "       'Member type', 'day_of_week', 'month', 'year', 'Total trip count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign independent and dependent variables based on \n",
        "pre_pandemic_X = pre_pandemic_data[['Start station number','End station number', 'Member type','day_of_week', 'month', 'year']]\n",
        "pre_pandemic_y = pre_pandemic_data['Total trip count']\n",
        "post_pandemic_X = post_pandemic_data[['Start station number','End station number', 'Member type','day_of_week', 'month', 'year']]\n",
        "post_pandemic_y = post_pandemic_data['Total trip count']\n",
        "\n",
        "# One-hot encode the 'Member type' column\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "pre_pandemic_X_encoded = pd.DataFrame(encoder.fit_transform(pre_pandemic_X[['Member type']]))\n",
        "pre_pandemic_X_encoded.columns = encoder.get_feature_names_out(['Member type'])\n",
        "pre_pandemic_X = pd.concat([pre_pandemic_X.drop('Member type', axis=1), pre_pandemic_X_encoded], axis=1)\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "lstm_params = [\n",
        "    {'units': 50, 'epochs': 50, 'batch_size': 32},\n",
        "    {'units': 100, 'epochs': 100, 'batch_size': 64},\n",
        "    {'units': 200, 'epochs': 100, 'batch_size': 128}\n",
        "]\n",
        "\n",
        "rf_params = [\n",
        "    {'n_estimators': 100},\n",
        "    {'n_estimators': 200},\n",
        "    {'n_estimators': 300}\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uba2Gst34RY4",
        "outputId": "50487055-ead0-4834-e1ca-2e005d5dc47d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform model training and evaluation for each set of hyperparameters\n",
        "results = []\n",
        "\n",
        "for lstm_param in lstm_params:\n",
        "    for rf_param in rf_params:\n",
        "        # LSTM Model\n",
        "        # Split the pre-pandemic data into train and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(pre_pandemic_X, pre_pandemic_y, test_size=0.2, random_state=42)\n",
        "        \n",
        "        # Normalize the data\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Reshape the input data for LSTM\n",
        "        X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "        X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "        # Build the LSTM model\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(lstm_param['units'], activation='relu', input_shape=(1, X_train_scaled.shape[1])))\n",
        "        model.add(Dense(1))\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        # Train the LSTM model\n",
        "        model.fit(X_train_reshaped, y_train, epochs=lstm_param['epochs'], batch_size=lstm_param['batch_size'], verbose=0)\n",
        "\n",
        "        # Evaluate the LSTM model\n",
        "        y_pred_lstm = model.predict(X_test_reshaped)\n",
        "        mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
        "\n",
        "        # Ensemble Model\n",
        "        # Train a Random Forest regressor on the post-pandemic data\n",
        "        model_rf = RandomForestRegressor(**rf_param, random_state=42)\n",
        "        model_rf.fit(post_pandemic_X, post_pandemic_y)\n",
        "\n",
        "        # Predict using the Random Forest regressor\n",
        "        y_pred_rf = model_rf.predict(X_test)\n",
        "        mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "        # Combine the predictions using simple averaging\n",
        "        y_pred_ensemble = (y_pred_lstm + y_pred_rf) / 2\n",
        "        mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n",
        "\n",
        "        # Store the results\n",
        "        result = {\n",
        "            'LSTM Parameters': lstm_param,\n",
        "            'Random Forest Parameters': rf_param,\n",
        "            'LSTM MSE': mse_lstm,\n",
        "            'Random Forest MSE': mse_rf,\n",
        "            'Ensemble MSE': mse_ensemble\n",
        "        }\n",
        "        results.append(result)"
      ],
      "metadata": {
        "id": "_yOr2EVdfMhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "for result in results:\n",
        "    print(f\"LSTM Parameters: {result['LSTM Parameters']}\")\n",
        "    print(f\"Random Forest Parameters: {result['Random Forest Parameters']}\")\n",
        "    print(f\"LSTM MSE: {result['LSTM MSE']}\")\n",
        "    print(f\"Random Forest MSE: {result['Random Forest MSE']}\")\n",
        "    print(f\"Ensemble MSE: {result['Ensemble MSE']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "jbx6EdcgfOKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}